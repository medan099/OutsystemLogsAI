# ðŸ§  OutsystemLogsAI 

This project demonstrates how to build a Retrieval-Augmented Generation (RAG) system to assist developers with OutSystems-related issues, using open-source LLMs (Mistral and Phi-3) via Ollama.

## ðŸš€ Features  

âœ… Custom dataset of OutSystems problems & solutions (from real logs from outsystems forums)

âœ… Preprocessing scripts (web scraping , base64 conversion, cleaning)

âœ… Image screenshots from OutSystems forums were automatically converted into descriptive text using Google Gemini LLM, enriching the dataset

âœ… Smart document ranking with keyword & screenshot metadata

âœ… LangChain-based RAG setup

âœ… Works with either Mistral or Phi-3 (via Ollama)

## ðŸ“¦ Requirements

Install the required dependencies:

-pip install langchain faiss-cpu transformers

To use Ollama LLMs:


-curl -fsSL https://ollama.com/install.sh | sh

-ollama run mistral

-ollama run phi3

## ðŸ“Š Dataset

The dataset is enriched with real-world problems and solutions from OutSystems forums. It includes:

-Cleaned text from user posts

-Automatically generated image descriptions (from forum screenshots)

-Keyword-based metadata (e.g., technical keywords, error detection)

ðŸ“¥ Available on Kaggle:

https://www.kaggle.com/datasets/mohamedanoun/final-dataset

Note: You can directly run the notebooks using this dataset â€” it's already preprocessed and ready for implementing the RAG models.

Make sure to download and place it in the appropriate location in the repo.

## ðŸ§ª Notebooks

| Notebook                                        | Description                                      |
| ----------------------------------------------- | ------------------------------------------------ |
| `Generating-Model-With-RAG-Using-Mistral.ipynb` | Implements RAG pipeline using Mistral via Ollama |
| `Generating-Model-With-RAG-Using-Phi3.ipynb`    | Implements RAG pipeline using Phi-3 via Ollama   |


## ðŸ’¡ Use Case

This system can be used by OutSystems developers and support engineers to:

-Understand errors from logs

-Get fast, structured troubleshooting advice

-Leverage past support cases to avoid reinventing the wheel

## ðŸ§  How It Works

The system follows dual logic:

ðŸ§© If similar logs exist in the dataset:

RAG retrieves the most relevant documents and provides a structured answer based on historical context.

ðŸ§  If no similar logs are found:

The LLM falls back to a general reasoning mode and generates a custom solution using its own knowledge base.

## ðŸ“Š Model Comparison
| Model   | Accuracy | Recommendation |
| ------- | -------- | -------------- |
| Phi-3   | 86.67%   | âœ… Recommended  |
| Mistral | 75.83%   | Optional       |


You can choose either model by switching a single parameter in the notebook.
However, Phi-3 is recommended for better accuracy and reasoning in technical cases.
